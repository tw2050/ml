{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_train_path = 'F:/ml-data/car-num/tf_car_license_dataset/train_images/training-set/letters/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ch(file_name):\n",
    "    ret = ''\n",
    "    for ch in file_path:\n",
    "        if u'\\u4e00' <= ch <= u'\\u9fff': \n",
    "            ret += ch\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_ch(file_name, ch):\n",
    "    time_str = 'bk'\n",
    "    file_name = file_name.replace(ch, time_str)\n",
    "    return file_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 去除文件名中的中文--替换为bk  （存在中文字符cv2打不开）\n",
    "\n",
    "def filename_not_ch(file_path):\n",
    "    for root, dirs, files in os.walk(file_path):\n",
    "         for d in dirs:\n",
    "            data_dir = root + d\n",
    "            for root1, dirs1, file1 in os.walk(data_dir):\n",
    "                for f in file1:\n",
    "                    data_img_path = data_dir + '/' + f\n",
    "                    ch = get_ch(f)\n",
    "                    if ch:\n",
    "                        new_name = repeat_ch(f, ch)\n",
    "                        new_path = data_dir + '/' + new_name\n",
    "                        os.rename(data_img_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2arr(file_path):\n",
    "    img = cv2.imread(file_path, 2)\n",
    "    img_flatten = np.array(img).flatten()\n",
    "    return img_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dataset(dataset_path):\n",
    "    data = []\n",
    "    target = []\n",
    "\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for d in dirs:\n",
    "            data_dir = root + d\n",
    "            label = int(d) - 10\n",
    "            if label > 23:\n",
    "                break;\n",
    "            for root1, dirs1, file1 in os.walk(data_dir):\n",
    "                for f in file1:\n",
    "                    data_img_path = data_dir + '/' + f\n",
    "                    data_img_flatten = img2arr(data_img_path)\n",
    "                    data.append(data_img_flatten)\n",
    "                    target.append(label)\n",
    "    data1 = np.array(data)\n",
    "    target = np.array(target)\n",
    "    return data1, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3198, 1280)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_target = get_dataset(letter_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3198, 1280)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3198,)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(train_data, train_target, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2558, 1280)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 1280)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 数据转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 40\n",
    "IMG_WIDTH = 32\n",
    "\n",
    "train_x = train_x.reshape(train_x.shape[0], IMG_HEIGHT, IMG_WIDTH, 1)/255\n",
    "test_x = test_x.reshape(test_x.shape[0], IMG_HEIGHT, IMG_WIDTH, 1)/255\n",
    "train_y = keras.utils.to_categorical(train_y, num_classes=24)\n",
    "test_y = keras.utils.to_categorical(test_y, num_classes=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2558, 40, 32, 1)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 40, 32, 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2558, 24)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 封装网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 40, 32, 50)        500       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 16, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 160)               2560160   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 80)                12880     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 24)                1944      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24)                0         \n",
      "=================================================================\n",
      "Total params: 2,575,484\n",
      "Trainable params: 2,575,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(50, (3,3), strides = 1, padding = 'same', activation = 'relu', input_shape = (IMG_HEIGHT, IMG_WIDTH, 1)))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(160))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(80))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(24))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 2558 samples, validate on 640 samples\n",
      "Epoch 1/15\n",
      "2558/2558 [==============================] - 2s 864us/step - loss: 1.8913 - accuracy: 0.4965 - val_loss: 0.7471 - val_accuracy: 0.8219\n",
      "Epoch 2/15\n",
      "2558/2558 [==============================] - 2s 780us/step - loss: 0.3484 - accuracy: 0.9308 - val_loss: 0.1109 - val_accuracy: 0.9859\n",
      "Epoch 3/15\n",
      "2558/2558 [==============================] - 2s 832us/step - loss: 0.0556 - accuracy: 0.9914 - val_loss: 0.0358 - val_accuracy: 0.9922\n",
      "Epoch 4/15\n",
      "2558/2558 [==============================] - 2s 778us/step - loss: 0.0188 - accuracy: 0.9969 - val_loss: 0.0233 - val_accuracy: 0.9953\n",
      "Epoch 5/15\n",
      "2558/2558 [==============================] - 2s 818us/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.0144 - val_accuracy: 0.9969\n",
      "Epoch 6/15\n",
      "2558/2558 [==============================] - 2s 787us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9969\n",
      "Epoch 7/15\n",
      "2558/2558 [==============================] - 2s 782us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9984\n",
      "Epoch 8/15\n",
      "2558/2558 [==============================] - 2s 784us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9969\n",
      "Epoch 9/15\n",
      "2558/2558 [==============================] - 2s 783us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "2558/2558 [==============================] - 2s 817us/step - loss: 9.9871e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "2558/2558 [==============================] - 2s 860us/step - loss: 8.9129e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "2558/2558 [==============================] - 2s 789us/step - loss: 7.9718e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "2558/2558 [==============================] - 2s 808us/step - loss: 7.3209e-04 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "2558/2558 [==============================] - 2s 797us/step - loss: 6.6135e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "2558/2558 [==============================] - 2s 867us/step - loss: 6.1202e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics= ['accuracy'])\n",
    "history = model.fit(train_x, train_y, batch_size=200, epochs=15, validation_data=(test_x, test_y), workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 40, 32, 1)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = test_x[:32]\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_dict = {\n",
    "    0:'A',\n",
    "    1:'B',\n",
    "    2:'C',\n",
    "    3:'D',\n",
    "    4:'E',\n",
    "    5:'F',\n",
    "    6:'G',\n",
    "    7:'H',\n",
    "    8:'J',\n",
    "    9:'K',\n",
    "    10:'L',\n",
    "    11:'M',\n",
    "    12:'N',\n",
    "    13:'P',\n",
    "    14:'Q',\n",
    "    15:'R',\n",
    "    16:'S',\n",
    "    17:'T',\n",
    "    18:'U',\n",
    "    19:'V',\n",
    "    20:'W',\n",
    "    21:'X',\n",
    "    22:'Y',\n",
    "    23:'Z'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_letter_predict(data, predict):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    for i in range(len(data)):\n",
    "        plt.subplot(4, 8, i +1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(data[i].reshape(40,32), cmap=\"binary\",  interpolation = 'nearest')\n",
    "        plt.title('predict: {} }'.format(ch_dict[predict[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 17, 15,  9,  1,  1,  0, 23,  0,  2], dtype=int64)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y = model.predict_classes(sample)\n",
    "predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_letter_predict(sample, predict_y,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
