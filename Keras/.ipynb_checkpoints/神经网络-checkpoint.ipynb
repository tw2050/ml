{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('F:/ml-data/indians-diabets/indians-diabets.txt', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[:, 0:8]\n",
    "y = dataset[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(12, input_dim = 8, activation = 'relu'))  # 第一层， １２个神经原\n",
    "#model.add(Dense(8, activation = 'relu'))                  # 第二层，　８个神经原\n",
    "model.add(Dense(1, activation = 'sigmoid'))               # 第三层， 由于二分类， 使用sigmoid函数激活， 多分类采用softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s 788us/step - loss: 0.6671 - accuracy: 0.6510\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 322us/step - loss: 0.6483 - accuracy: 0.6510\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.6467 - accuracy: 0.6510\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 322us/step - loss: 0.6461 - accuracy: 0.6510\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.6454 - accuracy: 0.6510\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.6456 - accuracy: 0.6510\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 319us/step - loss: 0.6453 - accuracy: 0.6510\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.6458 - accuracy: 0.6510\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 322us/step - loss: 0.6441 - accuracy: 0.6510\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.6424 - accuracy: 0.6510\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.6402 - accuracy: 0.6510\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.6379 - accuracy: 0.6510\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.6367 - accuracy: 0.6510\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 322us/step - loss: 0.6346 - accuracy: 0.6510\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.6330 - accuracy: 0.6510\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.6330 - accuracy: 0.6510\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.6317 - accuracy: 0.6510\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.6292 - accuracy: 0.6510\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 408us/step - loss: 0.6323 - accuracy: 0.6510\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 317us/step - loss: 0.6309 - accuracy: 0.6510\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 382us/step - loss: 0.6293 - accuracy: 0.6510\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.6294 - accuracy: 0.6510\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 330us/step - loss: 0.6284 - accuracy: 0.6510\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 319us/step - loss: 0.6265 - accuracy: 0.6510\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 378us/step - loss: 0.6297 - accuracy: 0.6510\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 334us/step - loss: 0.6249 - accuracy: 0.6510\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.6259 - accuracy: 0.6510\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 366us/step - loss: 0.6256 - accuracy: 0.6510\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 330us/step - loss: 0.6244 - accuracy: 0.6549\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 366us/step - loss: 0.6256 - accuracy: 0.6719\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.6254 - accuracy: 0.6745\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 373us/step - loss: 0.6252 - accuracy: 0.6732\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 390us/step - loss: 0.6249 - accuracy: 0.6706\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 338us/step - loss: 0.6234 - accuracy: 0.6745\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 478us/step - loss: 0.6204 - accuracy: 0.6784\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.6167 - accuracy: 0.68 - 0s 309us/step - loss: 0.6237 - accuracy: 0.6745\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.6265 - accuracy: 0.6706\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.6207 - accuracy: 0.6849\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.6231 - accuracy: 0.6758\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.6208 - accuracy: 0.6888\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.6282 - accuracy: 0.66 - 0s 308us/step - loss: 0.6250 - accuracy: 0.6706\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 374us/step - loss: 0.6218 - accuracy: 0.6797\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.6223 - accuracy: 0.6797\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 391us/step - loss: 0.6185 - accuracy: 0.6901\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 329us/step - loss: 0.6204 - accuracy: 0.6849\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 321us/step - loss: 0.6226 - accuracy: 0.6836\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 377us/step - loss: 0.6208 - accuracy: 0.6823\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.6236 - accuracy: 0.6862\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 364us/step - loss: 0.6180 - accuracy: 0.6823\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.6178 - accuracy: 0.6849\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 339us/step - loss: 0.6207 - accuracy: 0.6914\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.6169 - accuracy: 0.6836\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 340us/step - loss: 0.6172 - accuracy: 0.6875\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 330us/step - loss: 0.6194 - accuracy: 0.6888\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.6182 - accuracy: 0.68880s - loss: 0.6520 - accuracy: \n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 392us/step - loss: 0.6233 - accuracy: 0.6758\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 327us/step - loss: 0.6180 - accuracy: 0.6953\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 370us/step - loss: 0.6172 - accuracy: 0.6875\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 332us/step - loss: 0.6181 - accuracy: 0.6875\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 339us/step - loss: 0.6136 - accuracy: 0.6927\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.6156 - accuracy: 0.6940\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.6135 - accuracy: 0.6979\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 344us/step - loss: 0.6156 - accuracy: 0.6901\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.6133 - accuracy: 0.6966\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 332us/step - loss: 0.6167 - accuracy: 0.6914\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.6119 - accuracy: 0.6953\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.6126 - accuracy: 0.6953\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 364us/step - loss: 0.6128 - accuracy: 0.6940\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 322us/step - loss: 0.6141 - accuracy: 0.69530s - loss: 0.6132 - accuracy: 0.\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 319us/step - loss: 0.6161 - accuracy: 0.6901\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.6123 - accuracy: 0.6927\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.6271 - accuracy: 0.6706\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 399us/step - loss: 0.6172 - accuracy: 0.6836\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.6150 - accuracy: 0.6888\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.6126 - accuracy: 0.7005\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.6123 - accuracy: 0.7005\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.6101 - accuracy: 0.6992\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 338us/step - loss: 0.6159 - accuracy: 0.6914\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.6150 - accuracy: 0.6979\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.6140 - accuracy: 0.6914\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.6157 - accuracy: 0.6901\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 336us/step - loss: 0.6117 - accuracy: 0.6953\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 327us/step - loss: 0.6152 - accuracy: 0.6940\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 321us/step - loss: 0.6186 - accuracy: 0.6810\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.6130 - accuracy: 0.7005\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.6067 - accuracy: 0.7044\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.6106 - accuracy: 0.7005\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 380us/step - loss: 0.6095 - accuracy: 0.69790s - loss: 0.6116 - accuracy: \n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 404us/step - loss: 0.6140 - accuracy: 0.6927\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 383us/step - loss: 0.6107 - accuracy: 0.69920s - loss: 0.6140 - accuracy: \n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 364us/step - loss: 0.6081 - accuracy: 0.7005\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 360us/step - loss: 0.6110 - accuracy: 0.6992\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 349us/step - loss: 0.6094 - accuracy: 0.7018\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 386us/step - loss: 0.6083 - accuracy: 0.7044\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.6125 - accuracy: 0.6940\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 330us/step - loss: 0.6077 - accuracy: 0.70180s - loss: 0.5837 - accuracy\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.6047 - accuracy: 0.70440s - loss: 0.5993 - accuracy: 0.\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.6090 - accuracy: 0.6979\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.6080 - accuracy: 0.7018\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.6083 - accuracy: 0.70180s - loss: 0.5807 - accuracy: \n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 338us/step - loss: 0.6070 - accuracy: 0.7031\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.6151 - accuracy: 0.6940\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 319us/step - loss: 0.6098 - accuracy: 0.7005\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.6079 - accuracy: 0.7018\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.6081 - accuracy: 0.69920s - loss: 0.6185 - accuracy: \n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 322us/step - loss: 0.6055 - accuracy: 0.7057\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.6058 - accuracy: 0.7031\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 317us/step - loss: 0.6069 - accuracy: 0.7096\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 319us/step - loss: 0.6143 - accuracy: 0.6914\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.6078 - accuracy: 0.7057\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.6054 - accuracy: 0.7096\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 327us/step - loss: 0.6048 - accuracy: 0.7109\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 329us/step - loss: 0.6049 - accuracy: 0.7096\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.6061 - accuracy: 0.7018\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.6056 - accuracy: 0.7031\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.6051 - accuracy: 0.7070\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.6031 - accuracy: 0.7122\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.6118 - accuracy: 0.69270s - loss: 0.6115 - accuracy: \n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 273us/step - loss: 0.6146 - accuracy: 0.6940\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 319us/step - loss: 0.6094 - accuracy: 0.6927\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 395us/step - loss: 0.6058 - accuracy: 0.7044\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.6054 - accuracy: 0.7031\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 358us/step - loss: 0.6039 - accuracy: 0.7083\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.6045 - accuracy: 0.70570s - loss: 0.6052 - accuracy: 0.70\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.6049 - accuracy: 0.7109\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.6057 - accuracy: 0.7018\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.6087 - accuracy: 0.7005\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.6072 - accuracy: 0.7031\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.6048 - accuracy: 0.7096\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.6063 - accuracy: 0.7031\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 273us/step - loss: 0.6146 - accuracy: 0.6888\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 399us/step - loss: 0.6112 - accuracy: 0.69400s - loss: 0.6156 - accuracy: \n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.6046 - accuracy: 0.7070\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.6100 - accuracy: 0.6914\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 410us/step - loss: 0.6142 - accuracy: 0.68880s - loss: 0.5561 - accura\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.6066 - accuracy: 0.7018\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.6017 - accuracy: 0.7161\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 391us/step - loss: 0.6039 - accuracy: 0.7083\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 364us/step - loss: 0.6039 - accuracy: 0.7083\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 332us/step - loss: 0.6026 - accuracy: 0.7096\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 334us/step - loss: 0.6010 - accuracy: 0.7122\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 319us/step - loss: 0.6053 - accuracy: 0.7070\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.6152 - accuracy: 0.6875\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 336us/step - loss: 0.6038 - accuracy: 0.7057\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.6115 - accuracy: 0.69 - 0s 327us/step - loss: 0.6082 - accuracy: 0.7031\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.6067 - accuracy: 0.7005\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 365us/step - loss: 0.6024 - accuracy: 0.7096\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.6034 - accuracy: 0.7096\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 406us/step - loss: 0.6154 - accuracy: 0.6836\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.6099 - accuracy: 0.6966\n",
      "768/768 [==============================] - 0s 192us/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])  # 编译模型， \n",
    "model.fit(x, y, epochs=150, batch_size=10)\n",
    "_, accuracy = model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.96\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %0.2f' % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增加隐藏层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, activation = 'relu'))  # 第一层， １２个神经原\n",
    "model.add(Dense(8, activation = 'relu'))                  # 第二层，　８个神经原\n",
    "model.add(Dense(3, activation = 'relu'))                  # 第三层，　3个神经原\n",
    "model.add(Dense(1, activation = 'sigmoid'))               # 第四层， 由于二分类， 使用sigmoid函数激活， 多分类采用softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s 595us/step - loss: 3.6840 - accuracy: 0.5677\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 238us/step - loss: 1.9784 - accuracy: 0.5326\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 258us/step - loss: 1.3469 - accuracy: 0.5599\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.9417 - accuracy: 0.5964\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.7209 - accuracy: 0.6549\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 273us/step - loss: 0.6723 - accuracy: 0.6497\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 219us/step - loss: 0.6321 - accuracy: 0.6693\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.6242 - accuracy: 0.66150s - loss: 0.6198 - accuracy\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5992 - accuracy: 0.6901\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 242us/step - loss: 0.5952 - accuracy: 0.6914\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 249us/step - loss: 0.6084 - accuracy: 0.6745\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.5830 - accuracy: 0.6979\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5996 - accuracy: 0.6797\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.5894 - accuracy: 0.6836\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.5809 - accuracy: 0.68880s - loss: 0.5625 - accuracy: 0.\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 313us/step - loss: 0.5666 - accuracy: 0.70050s - loss: 0.5835 - accuracy\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.5846 - accuracy: 0.7018\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 256us/step - loss: 0.5804 - accuracy: 0.6927\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.5648 - accuracy: 0.7057\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 255us/step - loss: 0.5567 - accuracy: 0.7135\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 382us/step - loss: 0.5522 - accuracy: 0.7240\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 391us/step - loss: 0.5621 - accuracy: 0.71090s - loss: 0.5364 - accuracy\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 240us/step - loss: 0.5583 - accuracy: 0.7122\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 304us/step - loss: 0.5628 - accuracy: 0.7161\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 268us/step - loss: 0.5482 - accuracy: 0.7148\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 330us/step - loss: 0.5434 - accuracy: 0.7240\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5522 - accuracy: 0.7266\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 249us/step - loss: 0.5502 - accuracy: 0.7161\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.5875 - accuracy: 0.6888\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 256us/step - loss: 0.5570 - accuracy: 0.7083\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5445 - accuracy: 0.7148\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 257us/step - loss: 0.5503 - accuracy: 0.7135\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 256us/step - loss: 0.5399 - accuracy: 0.7240\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.5544 - accuracy: 0.7227\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.5414 - accuracy: 0.7135\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.5473 - accuracy: 0.7174\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.5399 - accuracy: 0.7044\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.5351 - accuracy: 0.7188\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5444 - accuracy: 0.72270s - loss: 0.5357 - accuracy: 0.72\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.5338 - accuracy: 0.7279\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5403 - accuracy: 0.7318\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.5387 - accuracy: 0.7305\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.5322 - accuracy: 0.7305\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 268us/step - loss: 0.5337 - accuracy: 0.7253\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 309us/step - loss: 0.5410 - accuracy: 0.7344\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 255us/step - loss: 0.5265 - accuracy: 0.7383\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.5355 - accuracy: 0.7253\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 268us/step - loss: 0.5282 - accuracy: 0.7253\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.5311 - accuracy: 0.7331\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 334us/step - loss: 0.5382 - accuracy: 0.7188\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 330us/step - loss: 0.5293 - accuracy: 0.7279\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 327us/step - loss: 0.5225 - accuracy: 0.7318\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 360us/step - loss: 0.5178 - accuracy: 0.7357\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.5175 - accuracy: 0.7279\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 321us/step - loss: 0.5320 - accuracy: 0.7344\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 327us/step - loss: 0.5282 - accuracy: 0.7344\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 317us/step - loss: 0.5284 - accuracy: 0.7305\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.5168 - accuracy: 0.7474\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.5212 - accuracy: 0.7435\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 248us/step - loss: 0.5214 - accuracy: 0.7370\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5177 - accuracy: 0.7500\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.5173 - accuracy: 0.73570s - loss: 0.4669 - accuracy: \n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5182 - accuracy: 0.74090s - loss: 0.5073 - accuracy: 0.\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 322us/step - loss: 0.5325 - accuracy: 0.7292\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5154 - accuracy: 0.7318\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 297us/step - loss: 0.5377 - accuracy: 0.7292\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.5085 - accuracy: 0.7513\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 255us/step - loss: 0.5203 - accuracy: 0.7253\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 256us/step - loss: 0.5124 - accuracy: 0.7344\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 356us/step - loss: 0.5113 - accuracy: 0.7552\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 256us/step - loss: 0.5059 - accuracy: 0.7448\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 256us/step - loss: 0.5166 - accuracy: 0.7331\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.5221 - accuracy: 0.75260s - loss: 0.5337 - accuracy\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5049 - accuracy: 0.7565\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 334us/step - loss: 0.5161 - accuracy: 0.7474\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.5157 - accuracy: 0.7461\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.5135 - accuracy: 0.7552\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.4955 - accuracy: 0.7669\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.5086 - accuracy: 0.7448\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.4983 - accuracy: 0.74870s - loss: 0.4965 - accuracy: 0.74\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.5004 - accuracy: 0.75260s - loss: 0.4743 - accuracy\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.5108 - accuracy: 0.7630\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.4986 - accuracy: 0.7552\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 256us/step - loss: 0.4951 - accuracy: 0.7578\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.4998 - accuracy: 0.7526\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.5060 - accuracy: 0.7643\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.5024 - accuracy: 0.7578\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.5085 - accuracy: 0.7552\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.4914 - accuracy: 0.7578\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.4904 - accuracy: 0.7591\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.4981 - accuracy: 0.7513\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4812 - accuracy: 0.7708\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 255us/step - loss: 0.4978 - accuracy: 0.76040s - loss: 0.5182 - accuracy: 0.\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.4809 - accuracy: 0.7799\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.4864 - accuracy: 0.7643\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.4850 - accuracy: 0.7695\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 256us/step - loss: 0.4807 - accuracy: 0.7708\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 257us/step - loss: 0.4879 - accuracy: 0.7708\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 268us/step - loss: 0.4947 - accuracy: 0.7539\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.4829 - accuracy: 0.7734\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 316us/step - loss: 0.4822 - accuracy: 0.7565\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.4773 - accuracy: 0.7799\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 249us/step - loss: 0.4914 - accuracy: 0.7604\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.4869 - accuracy: 0.7812\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.4895 - accuracy: 0.7630\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.4747 - accuracy: 0.7786\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.4820 - accuracy: 0.7773\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 245us/step - loss: 0.4819 - accuracy: 0.7695\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 225us/step - loss: 0.4851 - accuracy: 0.7643\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.4760 - accuracy: 0.7656\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.4771 - accuracy: 0.76950s - loss: 0.4851 - accuracy: 0.\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.4826 - accuracy: 0.7760\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.4801 - accuracy: 0.7682\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.4949 - accuracy: 0.7461\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 319us/step - loss: 0.4714 - accuracy: 0.7826\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.4731 - accuracy: 0.7773\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 248us/step - loss: 0.4839 - accuracy: 0.7604\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.4743 - accuracy: 0.7747\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.4783 - accuracy: 0.7799\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.4828 - accuracy: 0.7578\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 447us/step - loss: 0.4866 - accuracy: 0.76300s - loss: 0.4527 - accura\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.4763 - accuracy: 0.7773\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 309us/step - loss: 0.4748 - accuracy: 0.7747\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.4766 - accuracy: 0.7604\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.4797 - accuracy: 0.7747\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 383us/step - loss: 0.4781 - accuracy: 0.7708\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.4677 - accuracy: 0.7760\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4709 - accuracy: 0.7669\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.4680 - accuracy: 0.7839\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4650 - accuracy: 0.7786\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.4834 - accuracy: 0.7656\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 256us/step - loss: 0.4857 - accuracy: 0.7669\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 255us/step - loss: 0.4711 - accuracy: 0.7617\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.4687 - accuracy: 0.7812\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.4748 - accuracy: 0.7721\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.4702 - accuracy: 0.77990s - loss: 0.4757 - accuracy: 0.77\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.4749 - accuracy: 0.7734\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.4638 - accuracy: 0.7695\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.4609 - accuracy: 0.7852\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 243us/step - loss: 0.4699 - accuracy: 0.7708\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.4657 - accuracy: 0.7956\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 297us/step - loss: 0.4684 - accuracy: 0.78260s - loss: 0.4617 - accuracy: \n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 248us/step - loss: 0.4681 - accuracy: 0.7734\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.4583 - accuracy: 0.7852\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 369us/step - loss: 0.4771 - accuracy: 0.7786\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.4623 - accuracy: 0.7943\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 257us/step - loss: 0.4603 - accuracy: 0.7930\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 330us/step - loss: 0.4643 - accuracy: 0.7786\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.4707 - accuracy: 0.7708\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 268us/step - loss: 0.4736 - accuracy: 0.7682\n",
      "768/768 [==============================] - 0s 184us/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])  # 编译模型， \n",
    "model.fit(x, y, epochs=150, batch_size=10)\n",
    "_, accuracy = model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.26\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %0.2f' % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => (predict 0) (real 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => (predict 0) (real 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => (predict 0) (real 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => (predict 0) (real 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => (predict 1) (real 1)\n",
      "[5.0, 116.0, 74.0, 0.0, 0.0, 25.6, 0.201, 30.0] => (predict 0) (real 0)\n",
      "[3.0, 78.0, 50.0, 32.0, 88.0, 31.0, 0.248, 26.0] => (predict 1) (real 1)\n",
      "[10.0, 115.0, 0.0, 0.0, 0.0, 35.3, 0.134, 29.0] => (predict 0) (real 0)\n",
      "[2.0, 197.0, 70.0, 45.0, 543.0, 30.5, 0.158, 53.0] => (predict 1) (real 1)\n",
      "[8.0, 125.0, 96.0, 0.0, 0.0, 0.0, 0.232, 54.0] => (predict 0) (real 1)\n"
     ]
    }
   ],
   "source": [
    "prdict_y = model.predict_classes(x)\n",
    "for i in range(10):\n",
    "    print('%s => (predict %d) (real %d)' % (x[i].tolist(), prdict_y[i], y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 参数 epochs, batch_size 批次及 批次大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim = 8, activation = 'relu'))\n",
    "    model.add(Dense(8, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {\n",
    "    'epochs': [10, 50, 100],\n",
    "    'batch_size': [10, 20, 40, 60, 80, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=model, param_grid=grid_param, n_jobs=-1, verbose=True, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "e:\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "gs_ret = gs.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.72 using {'batch_size': 10, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print('Best: %0.2f using %s' %(gs_ret.best_score_, gs_ret.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.623698 (0.012890) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.675781 (0.027251) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.716146 (0.012890) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.488281 (0.091276) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.670573 (0.003683) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.694010 (0.014382) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.555990 (0.035849) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.664062 (0.024910) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.690104 (0.030978) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.519531 (0.027621) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.652344 (0.011500) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.643229 (0.016367) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.505208 (0.022402) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.638021 (0.001841) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.654948 (0.011201) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.579427 (0.049445) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.617188 (0.035943) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.625000 (0.055335) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "means = gs_ret.cv_results_['mean_test_score']\n",
    "stds = gs_ret.cv_results_['std_test_score']\n",
    "params = gs_ret.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 参数 optimizer 优化函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer = 'adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim = 8, activation = 'relu'))\n",
    "    model.add(Dense(8, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs = 100, batch_size = 10, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {\n",
    "    'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(estimator= model, param_grid=grid_param, verbose=True, n_jobs= -1, cv = 3)\n",
    "gs_ret = gs.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.70 using {'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "print('Best: %0.2f using %s' %(gs_ret.best_score_, gs_ret.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.649740 (0.029635) with: {'optimizer': 'SGD'}\n",
      "0.671875 (0.003189) with: {'optimizer': 'RMSprop'}\n",
      "0.686198 (0.019488) with: {'optimizer': 'Adagrad'}\n",
      "0.664062 (0.042192) with: {'optimizer': 'Adadelta'}\n",
      "0.695312 (0.025315) with: {'optimizer': 'Adam'}\n",
      "0.688802 (0.004872) with: {'optimizer': 'Adamax'}\n",
      "0.694010 (0.040637) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "means = gs_ret.cv_results_['mean_test_score']\n",
    "stds = gs_ret.cv_results_['std_test_score']\n",
    "params = gs_ret.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 参数 learn_rate, momentum  随机梯度下降法的学习率， 以及动量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learn_rate = 0.01, momentum = 0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim = 8, activation = 'relu'))\n",
    "    model.add(Dense(8, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    sgd = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs = 100, batch_size = 10, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {\n",
    "    'learn_rate': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'momentum': [0, 0.2, 0.4, 0.6, 0.8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.1min\n",
      "e:\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:  3.6min finished\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(estimator= model, param_grid=grid_param, verbose=True, n_jobs= -1, cv = 3)\n",
    "gs_ret = gs.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.691406 using {'learn_rate': 0.01, 'momentum': 0.4}\n",
      "0.666667 (0.027126) with: {'learn_rate': 0.001, 'momentum': 0}\n",
      "0.670573 (0.021236) with: {'learn_rate': 0.001, 'momentum': 0.2}\n",
      "0.666667 (0.010253) with: {'learn_rate': 0.001, 'momentum': 0.4}\n",
      "0.664062 (0.017758) with: {'learn_rate': 0.001, 'momentum': 0.6}\n",
      "0.660156 (0.014616) with: {'learn_rate': 0.001, 'momentum': 0.8}\n",
      "0.648438 (0.022326) with: {'learn_rate': 0.01, 'momentum': 0}\n",
      "0.688802 (0.029635) with: {'learn_rate': 0.01, 'momentum': 0.2}\n",
      "0.691406 (0.026107) with: {'learn_rate': 0.01, 'momentum': 0.4}\n",
      "0.677083 (0.004872) with: {'learn_rate': 0.01, 'momentum': 0.6}\n",
      "0.647135 (0.030145) with: {'learn_rate': 0.01, 'momentum': 0.8}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.1, 'momentum': 0}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.1, 'momentum': 0.2}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.1, 'momentum': 0.4}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.1, 'momentum': 0.6}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.1, 'momentum': 0.8}\n",
      "0.649740 (0.024360) with: {'learn_rate': 0.2, 'momentum': 0}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.2, 'momentum': 0.2}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.2, 'momentum': 0.4}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.2, 'momentum': 0.6}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.2, 'momentum': 0.8}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.5, 'momentum': 0}\n",
      "0.652344 (0.026107) with: {'learn_rate': 0.5, 'momentum': 0.2}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.5, 'momentum': 0.4}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.5, 'momentum': 0.6}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.5, 'momentum': 0.8}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (gs_ret.best_score_, gs_ret.best_params_))\n",
    "means = gs_ret.cv_results_['mean_test_score']\n",
    "stds = gs_ret.cv_results_['std_test_score']\n",
    "params = gs_ret.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 参数kernel_initializer  全连接层权值初始化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(kernel_initializer = 'uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim = 8, kernel_initializer= kernel_initializer, activation = 'relu'))\n",
    "    model.add(Dense(8, kernel_initializer = kernel_initializer, activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer = kernel_initializer, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "768/768 [==============================] - 0s 601us/step - loss: 0.6806 - accuracy: 0.6263\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.6596 - accuracy: 0.6510\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 243us/step - loss: 0.6516 - accuracy: 0.6536\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.6427 - accuracy: 0.6693\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.6305 - accuracy: 0.6615\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 223us/step - loss: 0.6381 - accuracy: 0.6367\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.6139 - accuracy: 0.6888\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 242us/step - loss: 0.6041 - accuracy: 0.6836\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.5977 - accuracy: 0.6875\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.5934 - accuracy: 0.6940\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5936 - accuracy: 0.7005\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.5997 - accuracy: 0.6706\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.5905 - accuracy: 0.6940\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.5932 - accuracy: 0.7031\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 309us/step - loss: 0.5879 - accuracy: 0.6979\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.5868 - accuracy: 0.7005\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.5814 - accuracy: 0.7083\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.5797 - accuracy: 0.70310s - loss: 0.5850 - accuracy: 0.\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.5769 - accuracy: 0.7018\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5838 - accuracy: 0.6927\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 245us/step - loss: 0.5796 - accuracy: 0.7109\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.5822 - accuracy: 0.6953\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 309us/step - loss: 0.5796 - accuracy: 0.7005\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.5782 - accuracy: 0.6940\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.5736 - accuracy: 0.7018\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.5754 - accuracy: 0.6927\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 316us/step - loss: 0.5743 - accuracy: 0.7031\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 313us/step - loss: 0.5734 - accuracy: 0.70830s - loss: 0.5550 - accuracy: 0.\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.5727 - accuracy: 0.7096\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.5690 - accuracy: 0.7083\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 240us/step - loss: 0.5703 - accuracy: 0.6927\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.5694 - accuracy: 0.7122\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 304us/step - loss: 0.5708 - accuracy: 0.7109\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 313us/step - loss: 0.5747 - accuracy: 0.6953\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 268us/step - loss: 0.5657 - accuracy: 0.7266\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.5690 - accuracy: 0.7174\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.5656 - accuracy: 0.7018\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.5615 - accuracy: 0.7188\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.5574 - accuracy: 0.7253\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.5574 - accuracy: 0.7279\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.5612 - accuracy: 0.7266\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.5538 - accuracy: 0.7201\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 238us/step - loss: 0.5593 - accuracy: 0.7370\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.5571 - accuracy: 0.7253\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5540 - accuracy: 0.7253\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.5488 - accuracy: 0.7292\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.5498 - accuracy: 0.7279\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.5470 - accuracy: 0.72530s - loss: 0.5244 - accuracy: \n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.5430 - accuracy: 0.73440s - loss: 0.5177 - accuracy: 0.\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.5428 - accuracy: 0.7435\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 218us/step - loss: 0.5362 - accuracy: 0.7409\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.5466 - accuracy: 0.7318\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 239us/step - loss: 0.5380 - accuracy: 0.7383\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 227us/step - loss: 0.5423 - accuracy: 0.7383\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.5364 - accuracy: 0.74220s - loss: 0.5365 - accuracy: 0.\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.5317 - accuracy: 0.7370\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 229us/step - loss: 0.5291 - accuracy: 0.7552\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 255us/step - loss: 0.5293 - accuracy: 0.7461\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.5247 - accuracy: 0.7487\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.5322 - accuracy: 0.7539\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5226 - accuracy: 0.7604\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 236us/step - loss: 0.5275 - accuracy: 0.7526\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 238us/step - loss: 0.5207 - accuracy: 0.76560s - loss: 0.5218 - accuracy: \n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 255us/step - loss: 0.5259 - accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.5305 - accuracy: 0.7539\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 245us/step - loss: 0.5360 - accuracy: 0.7331\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 256us/step - loss: 0.5141 - accuracy: 0.7591\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5175 - accuracy: 0.7526\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 257us/step - loss: 0.5149 - accuracy: 0.7513\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.5106 - accuracy: 0.7630\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.5168 - accuracy: 0.7565\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 260us/step - loss: 0.5146 - accuracy: 0.7565\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.5119 - accuracy: 0.7552\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.5108 - accuracy: 0.7513\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 274us/step - loss: 0.5061 - accuracy: 0.7604\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 251us/step - loss: 0.5119 - accuracy: 0.7539\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 221us/step - loss: 0.5024 - accuracy: 0.7630\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.5076 - accuracy: 0.7526\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 253us/step - loss: 0.5080 - accuracy: 0.7448\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 239us/step - loss: 0.5040 - accuracy: 0.7487\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.5064 - accuracy: 0.7565\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.5026 - accuracy: 0.7643\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.5002 - accuracy: 0.7591\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.4960 - accuracy: 0.75 - 0s 316us/step - loss: 0.5046 - accuracy: 0.7487\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 319us/step - loss: 0.5046 - accuracy: 0.75780s - loss: 0.4987 - accuracy: 0.\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.4967 - accuracy: 0.7617\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.4949 - accuracy: 0.7617\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.4923 - accuracy: 0.7630\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 297us/step - loss: 0.4959 - accuracy: 0.7669\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 270us/step - loss: 0.4959 - accuracy: 0.7773\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 255us/step - loss: 0.4906 - accuracy: 0.7812\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 327us/step - loss: 0.4891 - accuracy: 0.7773\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.4877 - accuracy: 0.7643\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.4942 - accuracy: 0.7695\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.4912 - accuracy: 0.7669\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 262us/step - loss: 0.4868 - accuracy: 0.77340s - loss: 0.4931 - accuracy: 0.77\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.4852 - accuracy: 0.7799\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.4920 - accuracy: 0.7695\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 240us/step - loss: 0.4897 - accuracy: 0.7682\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.4889 - accuracy: 0.7734\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs = 100, batch_size = 10)\n",
    "\n",
    "grid_param = {\n",
    "    'kernel_initializer': ['zero', 'one', 'uniform', 'normal', 'glorot_uniform', 'glorot_normal', 'he_normal', 'he_uniform']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator= model, param_grid=grid_param, cv = 3, verbose=True, n_jobs= -1)\n",
    "gs_ret = gs.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.729167  using {'kernel_initializer': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "print('Best: %f  using %s' % (gs_ret.best_score_, gs_ret.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651 (0.025) with: {'kernel_initializer': 'zero'}\n",
      "0.671 (0.008) with: {'kernel_initializer': 'one'}\n",
      "0.729 (0.023) with: {'kernel_initializer': 'uniform'}\n",
      "0.725 (0.016) with: {'kernel_initializer': 'normal'}\n",
      "0.712 (0.013) with: {'kernel_initializer': 'glorot_uniform'}\n",
      "0.704 (0.009) with: {'kernel_initializer': 'glorot_normal'}\n",
      "0.682 (0.027) with: {'kernel_initializer': 'he_normal'}\n",
      "0.691 (0.023) with: {'kernel_initializer': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "means = gs_ret.cv_results_['mean_test_score']\n",
    "stds = gs_ret.cv_results_['std_test_score']\n",
    "params = gs_ret.cv_results_['params']\n",
    "\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print('%0.3f (%0.3f) with: %r' %(mean, std, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 参数activation 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation = 'relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim = 8, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation = activation))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs = 100, batch_size = 10, verbose = 0)\n",
    "grid_param = {\n",
    "    'activation': ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "}\n",
    "gs = GridSearchCV(estimator= model, param_grid=grid_param, cv = 3, verbose=True, n_jobs= -1)\n",
    "gs_ret = gs.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.753906 using {'activation': 'softplus'}\n"
     ]
    }
   ],
   "source": [
    "print('Best: %f using %s' %(gs_ret.best_score_, gs_ret.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641927 (0.013279) with {'activation': 'softmax'}\n",
      "0.753906 (0.024910) with {'activation': 'softplus'}\n",
      "0.707031 (0.020915) with {'activation': 'softsign'}\n",
      "0.701823 (0.025976) with {'activation': 'relu'}\n",
      "0.647135 (0.021236) with {'activation': 'tanh'}\n",
      "0.666667 (0.027866) with {'activation': 'sigmoid'}\n",
      "0.654948 (0.039365) with {'activation': 'hard_sigmoid'}\n",
      "0.736979 (0.023939) with {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "means = gs_ret.cv_results_['mean_test_score']\n",
    "stds = gs_ret.cv_results_['std_test_score']\n",
    "params = gs_ret.cv_results_['params']\n",
    "\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print('%f (%f) with %r' %(mean, std, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 参数dropout_rate   弃权率  指在当前层接比率随机不激活一些维度， 可以减少算法的过拟合现象， 同时增加算法的运算效率\n",
    "### 参数kernel_constraint 指权重生成是的约束条件。这里采用的是MaxNorm 最大范数约束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def create_model(dropout_rate = '0.2', weight_constraint = 0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim = 8, kernel_initializer = 'uniform', activation = 'linear', \n",
    "                    kernel_constraint = maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(8, kernel_initializer = 'uniform', activation = 'linear',\n",
    "                    kernel_constraint = maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "e:\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  3.7min finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs = 100, batch_size = 10, verbose = 0)\n",
    "grid_param = {\n",
    "    'dropout_rate': [0.1,0.2,0.3,0.4,0.5,0.6],\n",
    "    'weight_constraint':[1,2,3]\n",
    "}\n",
    "gs = GridSearchCV(estimator=model, param_grid=grid_param, cv = 3, verbose=True, n_jobs=-1)\n",
    "gs_ret = gs.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.742188 using {'dropout_rate': 0.2, 'weight_constraint': 1}\n"
     ]
    }
   ],
   "source": [
    "print('Best: %f using %s' %(gs_ret.best_score_, gs_ret.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731771 (0.038582) with {'dropout_rate': 0.1, 'weight_constraint': 1}\n",
      "0.736979 (0.047877) with {'dropout_rate': 0.1, 'weight_constraint': 2}\n",
      "0.738281 (0.022326) with {'dropout_rate': 0.1, 'weight_constraint': 3}\n",
      "0.742188 (0.024910) with {'dropout_rate': 0.2, 'weight_constraint': 1}\n",
      "0.733073 (0.035132) with {'dropout_rate': 0.2, 'weight_constraint': 2}\n",
      "0.734375 (0.013902) with {'dropout_rate': 0.2, 'weight_constraint': 3}\n",
      "0.740885 (0.034104) with {'dropout_rate': 0.3, 'weight_constraint': 1}\n",
      "0.738281 (0.024910) with {'dropout_rate': 0.3, 'weight_constraint': 2}\n",
      "0.705729 (0.011201) with {'dropout_rate': 0.3, 'weight_constraint': 3}\n",
      "0.704427 (0.012075) with {'dropout_rate': 0.4, 'weight_constraint': 1}\n",
      "0.725260 (0.026557) with {'dropout_rate': 0.4, 'weight_constraint': 2}\n",
      "0.717448 (0.009744) with {'dropout_rate': 0.4, 'weight_constraint': 3}\n",
      "0.714844 (0.011049) with {'dropout_rate': 0.5, 'weight_constraint': 1}\n",
      "0.704427 (0.013279) with {'dropout_rate': 0.5, 'weight_constraint': 2}\n",
      "0.714844 (0.003189) with {'dropout_rate': 0.5, 'weight_constraint': 3}\n",
      "0.699219 (0.012758) with {'dropout_rate': 0.6, 'weight_constraint': 1}\n",
      "0.701823 (0.016367) with {'dropout_rate': 0.6, 'weight_constraint': 2}\n",
      "0.694010 (0.023939) with {'dropout_rate': 0.6, 'weight_constraint': 3}\n"
     ]
    }
   ],
   "source": [
    "means = gs_ret.cv_results_['mean_test_score']\n",
    "stds = gs_ret.cv_results_['std_test_score']\n",
    "params = gs_ret.cv_results_['params']\n",
    "\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print ('%f (%f) with %r' %(mean, std, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 参数neurons 隐藏层神经元数量 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neurons1 = 1, neurons2 = 1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons1, input_dim = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neurons2, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "e:\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:  5.8min finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs = 100, batch_size = 10, verbose = 0)\n",
    "grid_param = {\n",
    "    'neurons1': [1, 5, 10, 15, 20],\n",
    "    'neurons2': [1, 5, 10, 15, 20]\n",
    "}\n",
    "gs = GridSearchCV(estimator=model, param_grid=grid_param, cv =3, verbose=True, n_jobs=-1)\n",
    "gs_ret = gs.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.727865 using {'neurons1': 15, 'neurons2': 15}\n"
     ]
    }
   ],
   "source": [
    "print('Best: %f using %s' %(gs_ret.best_score_, gs_ret.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.665365 (0.035849) with {'neurons1': 1, 'neurons2': 1}\n",
      "0.664062 (0.039964) with {'neurons1': 1, 'neurons2': 5}\n",
      "0.651042 (0.024774) with {'neurons1': 1, 'neurons2': 10}\n",
      "0.651042 (0.024774) with {'neurons1': 1, 'neurons2': 15}\n",
      "0.651042 (0.024774) with {'neurons1': 1, 'neurons2': 20}\n",
      "0.651042 (0.024774) with {'neurons1': 5, 'neurons2': 1}\n",
      "0.699219 (0.022999) with {'neurons1': 5, 'neurons2': 5}\n",
      "0.690104 (0.051658) with {'neurons1': 5, 'neurons2': 10}\n",
      "0.674479 (0.008027) with {'neurons1': 5, 'neurons2': 15}\n",
      "0.696615 (0.006639) with {'neurons1': 5, 'neurons2': 20}\n",
      "0.671875 (0.043146) with {'neurons1': 10, 'neurons2': 1}\n",
      "0.707031 (0.033299) with {'neurons1': 10, 'neurons2': 5}\n",
      "0.723958 (0.032578) with {'neurons1': 10, 'neurons2': 10}\n",
      "0.708333 (0.027866) with {'neurons1': 10, 'neurons2': 15}\n",
      "0.713542 (0.040637) with {'neurons1': 10, 'neurons2': 20}\n",
      "0.674479 (0.011201) with {'neurons1': 15, 'neurons2': 1}\n",
      "0.716146 (0.017566) with {'neurons1': 15, 'neurons2': 5}\n",
      "0.720052 (0.030314) with {'neurons1': 15, 'neurons2': 10}\n",
      "0.727865 (0.038318) with {'neurons1': 15, 'neurons2': 15}\n",
      "0.718750 (0.027251) with {'neurons1': 15, 'neurons2': 20}\n",
      "0.651042 (0.024774) with {'neurons1': 20, 'neurons2': 1}\n",
      "0.725260 (0.016367) with {'neurons1': 20, 'neurons2': 5}\n",
      "0.721354 (0.030145) with {'neurons1': 20, 'neurons2': 10}\n",
      "0.721354 (0.027866) with {'neurons1': 20, 'neurons2': 15}\n",
      "0.717448 (0.019488) with {'neurons1': 20, 'neurons2': 20}\n"
     ]
    }
   ],
   "source": [
    "means = gs_ret.cv_results_['mean_test_score']\n",
    "stds = gs_ret.cv_results_['std_test_score']\n",
    "params = gs_ret.cv_results_['params']\n",
    "\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print ('%f (%f) with %r' %(mean, std, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "### full params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def create_model(neurons1 = 1, neurons2 = 1, init_model = 'uniform', activation = 'relu', \n",
    "                 dropout_rate = 0.2, weight_constraint = 0, optimizer = 'adam' ):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons1, input_dim = 8, kernel_initializer = init_model, activation = activation, kernel_constraint = maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, kernel_initializer = init_model, activation =activation, kernel_constraint = maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer = init_model, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_param = {\n",
    "    'neurons1': [1, 5, 10, 15, 20],\n",
    "    'neurons2': [1, 5, 10, 15, 20],\n",
    "    'init_model': ['uniform', 'normal', 'glorot_uniform', 'glorot_normal', 'he_normal', 'he_uniform'],\n",
    "    'activation': ['softmax','relu', 'tanh', 'sigmoid',  'linear'],\n",
    "    'dropout_rate': [0.1,0.2,0.5],\n",
    "    'weight_constraint': [1,2,3],\n",
    "    'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adam'],\n",
    "    'epochs': [10, 50, 100],\n",
    "    'batch_size': [ 20, 40, 60, 80]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "e:\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 33.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 40.0min finished\n"
     ]
    }
   ],
   "source": [
    "rs = RandomizedSearchCV(estimator= model, param_distributions=random_param, n_iter=500, cv = 3, verbose=True, n_jobs= -1)\n",
    "rs_ret = rs.fit(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: %f using %s 0.7122395833333334 {'weight_constraint': 3, 'optimizer': 'RMSprop', 'neurons2': 15, 'neurons1': 10, 'init_model': 'uniform', 'epochs': 100, 'dropout_rate': 0.2, 'batch_size': 80, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "print('Best: %f using %s', rs_ret.best_score_, rs_ret.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
