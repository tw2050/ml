{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_path = 'F:/ml-data/car-num/tf_car_license_dataset/train_images/training-set/'\n",
    "valid_num_path = 'F:/ml-data/car-num/tf_car_license_dataset/train_images/validation-set/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ch(file_name):\n",
    "    ret = ''\n",
    "    for ch in file_name:\n",
    "        if u'\\u4e00' <= ch <= u'\\u9fff': \n",
    "            ret += ch\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_ch(file_name, ch):\n",
    "    time_str = 'bk'\n",
    "    file_name = file_name.replace(ch, time_str)\n",
    "    return file_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 去除文件名中的中文--替换为bk  （存在中文字符cv2打不开）\n",
    "\n",
    "def filename_not_ch(file_path):\n",
    "    for root, dirs, files in os.walk(file_path):\n",
    "         for d in dirs:\n",
    "            data_dir = root + d\n",
    "            for root1, dirs1, file1 in os.walk(data_dir):\n",
    "                for f in file1:\n",
    "                    data_img_path = data_dir + '/' + f\n",
    "                    ch = get_ch(f)\n",
    "                    if ch:\n",
    "                        new_name = repeat_ch(f, ch)\n",
    "                        new_path = data_dir + '/' + new_name\n",
    "                        os.rename(data_img_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename_not_ch(train_num_path)\n",
    "#filename_not_ch(valid_num_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2arr(file_path):\n",
    "    img = cv2.imread(file_path, 2)\n",
    "    img_flatten = np.array(img).flatten()\n",
    "    return img_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset_path):\n",
    "    data = []\n",
    "    target = []\n",
    "\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for d in dirs:\n",
    "            if (d.isdigit()):\n",
    "                label = int(d)\n",
    "                data_dir = root + d\n",
    "                for root1, dirs1, file1 in os.walk(data_dir):\n",
    "                    for f in file1:\n",
    "                        data_img_path = data_dir + '/' + f\n",
    "                        data_img_flatten = img2arr(data_img_path)\n",
    "\n",
    "                        data.append(data_img_flatten)\n",
    "                        target.append(label)\n",
    "    data1 = np.array(data)\n",
    "    target = np.array(target)\n",
    "    return data1, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = get_dataset(train_num_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4285, 1280)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4285,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data, valid_target = get_dataset(valid_num_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1280)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(train_data, train_target, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3428, 1280)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(857, 1280)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 40\n",
    "IMG_WIDTH = 32\n",
    "train_x = train_x.reshape(train_x.shape[0], IMG_HEIGHT, IMG_WIDTH, 1) / 255\n",
    "test_x = test_x.reshape(test_x.shape[0], IMG_HEIGHT, IMG_WIDTH, 1) /255\n",
    "train_y = keras.utils.to_categorical(train_y, num_classes = 34)\n",
    "test_y = keras.utils.to_categorical(test_y, num_classes=34)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3428, 40, 32, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape\n",
    "\n",
    "\n",
    "### 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(857, 40, 32, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3428, 34)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(857, 34)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 40, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 40, 32, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 20, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 20480)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 160)               3276960   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 80)                12880     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 34)                2754      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 34)                0         \n",
      "=================================================================\n",
      "Total params: 3,301,170\n",
      "Trainable params: 3,301,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), strides = 1, padding = 'same', activation = 'relu', input_shape = (IMG_HEIGHT, IMG_WIDTH, 1)))\n",
    "model.add(Conv2D(64, (2,2), strides = 1, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(160))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(80))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(34))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3428 samples, validate on 857 samples\n",
      "Epoch 1/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 2.4998 - accuracy: 0.3183 - val_loss: 0.9859 - val_accuracy: 0.7888\n",
      "Epoch 2/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 1.1942 - accuracy: 0.6345 - val_loss: 0.2350 - val_accuracy: 0.9498\n",
      "Epoch 3/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.6219 - accuracy: 0.8043 - val_loss: 0.0958 - val_accuracy: 0.9872\n",
      "Epoch 4/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.4257 - accuracy: 0.8638 - val_loss: 0.0482 - val_accuracy: 0.9930\n",
      "Epoch 5/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.2964 - accuracy: 0.9011 - val_loss: 0.0265 - val_accuracy: 0.9942\n",
      "Epoch 6/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.2252 - accuracy: 0.9256 - val_loss: 0.0231 - val_accuracy: 0.9942\n",
      "Epoch 7/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.1994 - accuracy: 0.9376 - val_loss: 0.0177 - val_accuracy: 0.9965\n",
      "Epoch 8/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.1608 - accuracy: 0.9446 - val_loss: 0.0153 - val_accuracy: 0.9965\n",
      "Epoch 9/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.1412 - accuracy: 0.9560 - val_loss: 0.0089 - val_accuracy: 0.9977.1\n",
      "Epoch 10/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.1341 - accuracy: 0.9548 - val_loss: 0.0114 - val_accuracy: 0.9953\n",
      "Epoch 11/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.0994 - accuracy: 0.9691 - val_loss: 0.0130 - val_accuracy: 0.9953\n",
      "Epoch 12/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.1107 - accuracy: 0.9650 - val_loss: 0.0096 - val_accuracy: 0.9965\n",
      "Epoch 13/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.0853 - accuracy: 0.9711 - val_loss: 0.0075 - val_accuracy: 0.9988\n",
      "Epoch 14/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.0776 - accuracy: 0.9737 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "Epoch 15/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.0786 - accuracy: 0.9740 - val_loss: 0.0075 - val_accuracy: 0.9965\n",
      "Epoch 16/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.0822 - accuracy: 0.9740 - val_loss: 0.0053 - val_accuracy: 0.9977\n",
      "Epoch 17/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.0754 - accuracy: 0.9752 - val_loss: 0.0047 - val_accuracy: 0.9977\n",
      "Epoch 18/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.0678 - accuracy: 0.9770 - val_loss: 0.0047 - val_accuracy: 0.9977\n",
      "Epoch 19/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.0624 - accuracy: 0.9799 - val_loss: 0.0047 - val_accuracy: 0.9977\n",
      "Epoch 20/20\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 0.0580 - accuracy: 0.9819 - val_loss: 0.0058 - val_accuracy: 0.9977\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(train_x, train_y, batch_size=100, epochs=20, validation_data=(test_x, test_y), workers=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = valid_data.reshape(valid_data.shape[0], IMG_HEIGHT, IMG_WIDTH, 1)/255\n",
    "valid_y = keras.utils.to_categorical(valid_target, num_classes=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 595us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.019368500971722824, 0.9950000047683716]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = model.predict_classes(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_idx = []\n",
    "error_prdict = []\n",
    "error_true = []\n",
    "\n",
    "for i in range(valid_x.shape[0]):\n",
    "    if valid_target[i] != predict_y[i]:\n",
    "        error_idx.append(i)\n",
    "        error_prdict.append(predict_y[i])\n",
    "        error_true.append(valid_target[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_prdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0',\n",
       " 1: '1',\n",
       " 2: '2',\n",
       " 3: '3',\n",
       " 4: '4',\n",
       " 5: '5',\n",
       " 6: '6',\n",
       " 7: '7',\n",
       " 8: '8',\n",
       " 9: '9',\n",
       " 10: 'A',\n",
       " 11: 'B',\n",
       " 12: 'C',\n",
       " 13: 'D',\n",
       " 14: 'E',\n",
       " 15: 'F',\n",
       " 16: 'G',\n",
       " 17: 'H',\n",
       " 18: 'J',\n",
       " 19: 'K',\n",
       " 20: 'L',\n",
       " 21: 'M',\n",
       " 22: 'N',\n",
       " 23: 'P',\n",
       " 24: 'Q',\n",
       " 25: 'R',\n",
       " 26: 'S',\n",
       " 27: 'T',\n",
       " 28: 'U',\n",
       " 29: 'V',\n",
       " 30: 'W',\n",
       " 31: 'X',\n",
       " 32: 'Y',\n",
       " 33: 'Z'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_dict = {\n",
    "    0:'0',\n",
    "    1:'1',\n",
    "    2:'2',\n",
    "    3:'3',\n",
    "    4:'4',\n",
    "    5:'5',\n",
    "    6:'6',\n",
    "    7:'7',\n",
    "    8:'8',\n",
    "    9:'9',\n",
    "    10:'A',\n",
    "    11:'B',\n",
    "    12:'C',\n",
    "    13:'D',\n",
    "    14:'E',\n",
    "    15:'F',\n",
    "    16:'G',\n",
    "    17:'H',\n",
    "    18:'J',\n",
    "    19:'K',\n",
    "    20:'L',\n",
    "    21:'M',\n",
    "    22:'N',\n",
    "    23:'P',\n",
    "    24:'Q',\n",
    "    25:'R',\n",
    "    26:'S',\n",
    "    27:'T',\n",
    "    28:'U',\n",
    "    29:'V',\n",
    "    30:'W',\n",
    "    31:'X',\n",
    "    32:'Y',\n",
    "    33:'Z'\n",
    "}\n",
    "num_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_num(err_data, err_predict, err_true):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for i in range(len(err_data)):\n",
    "        plt.subplot(1, len(err_data), i +1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(err_data[i].reshape(IMG_HEIGHT,IMG_WIDTH), cmap=\"binary\",  interpolation = 'nearest')\n",
    "        plt.title('true: {}\\npredict: {}'.format(num_dict[err_true[i]], num_dict[err_predict[i]]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "err_data = valid_data[error_idx]\n",
    "plot_error_num(err_data, error_prdict, error_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
